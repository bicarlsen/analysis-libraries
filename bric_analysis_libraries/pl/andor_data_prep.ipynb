{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andor Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "import pkgutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from .. import standard_functions as std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__root_mod_path = os.path.abspath( os.path.join( __file__, '..' ) )\n",
    "_data_path = os.path.join( 'data', 'andor' )\n",
    "corrections = {}\n",
    "\n",
    "for v_path in glob.glob( os.path.join( __root_mod_path, _data_path, '*' ) ):\n",
    "    version = os.path.basename( v_path )\n",
    "    corrections[ version ] = {}\n",
    "    \n",
    "    for file in glob.glob( os.path.join( __root_mod_path, v_path, '*' ) ):\n",
    "        _, t = os.path.splitext( file )\n",
    "        t = t[ 1: ]  # remove extension separator\n",
    "        \n",
    "        corrections[ version ][ t ] = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience functions for common extractions\n",
    "\n",
    "def sample_from_file_name( file ):\n",
    "    name_search  = '^(.*?)' # use lazy matching\n",
    "    return std.metadata_from_file_name( name_search, file )\n",
    "    \n",
    "\n",
    "def angle_from_file_name( file ):\n",
    "    angle_search = '<>deg'\n",
    "    return std.metadata_from_file_name( angle_search, file, True )\n",
    "      \n",
    "    \n",
    "def power_from_file_name( file ):\n",
    "    power_search = '<>mw'\n",
    "    return std.metadata_from_file_name( power_search, file, True )\n",
    "    \n",
    "    \n",
    "def time_from_file_name( file ):\n",
    "    time_search  = '<>' \n",
    "    return std.metadata_from_file_name( time_search, file, True, decimal = 's' )\n",
    "\n",
    "\n",
    "def wavelength_from_file_name( file ):\n",
    "    wavelength_search = '<>nm'\n",
    "    return std.metadata_from_file_name( wavelength_search, file, True )\n",
    "\n",
    "\n",
    "def temperature_from_file_name( file ):\n",
    "    temperature_search = '<>'\n",
    "    return std.metadata_from_file_name( temperature_search, file, True, decimal = 'k' )\n",
    "\n",
    "\n",
    "def pressure_from_file_name( file ):\n",
    "    pressure_search = '<>hpa'\n",
    "    return std.metadata_from_file_name( pressure_search, file, True, decimal = 'p' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_metadata_value( file, metadata ):\n",
    "    \"\"\"\n",
    "    Gets metadata values from a file path\n",
    "    \n",
    "    :param file: The file path to search\n",
    "    :param metadata: The key of a standard metadata to retrieve\n",
    "        [ 'sample', 'power', 'wavelength', 'time' ]\n",
    "    :returns: A list of metadata values\n",
    "    \"\"\"\n",
    "    return getattr( sys.modules[ __name__ ], '{}_from_file_name'.format( metadata ) )( file )\n",
    "\n",
    "\n",
    "def get_standard_metadata_values( file, metadata ):\n",
    "    \"\"\"\n",
    "    Gets metadata values from a file path\n",
    "    \n",
    "    :param file: The file path to search\n",
    "    :param metadata: A list of standard metadata to retrieve\n",
    "        [ 'sample', 'power', 'wavelength', 'time' ]\n",
    "    :returns: A list of metadata values\n",
    "    \"\"\"\n",
    "    return [ getattr( sys.modules[ __name__ ], '{}_from_file_name'.format( meta ) )( file ) for meta in metadata ]\n",
    "\n",
    "\n",
    "def get_metadata_values( file, metadata ):\n",
    "    \"\"\"\n",
    "    Gets metadata values from a file path\n",
    "    \n",
    "    :param file: The file path to search\n",
    "    :param metadata: Metadata from the file name is turned into MultiIndex columns\n",
    "        + If list, use standard keywords to include in index [ 'sample', 'power', 'wavelength', 'time' ]\n",
    "        + If Dictionary, keys indicate level name, value is pattern to match\n",
    "            or another dictionary with 'search' key being the pattern to match, and additional\n",
    "            entries matching arguments passed to standard_functions#metadata_from_filename.\n",
    "            + Reseserved key 'standard' can be provided with a list value to get standard metadata\n",
    "    :returns: A list of metadata values\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance( metadata, list ):\n",
    "        # use standard metadata\n",
    "        return get_standard_metadata_values( file, metadata )\n",
    "\n",
    "        \n",
    "    if isinstance( metadata, dict ):\n",
    "        # use custom metadata\n",
    "        # key is name, value is regexp pattern or dictionary with pattern and arguments\n",
    "\n",
    "        header_names = list( metadata.keys() )\n",
    "        \n",
    "        # get number of values\n",
    "        val_len = len( header_names )\n",
    "        if 'standard' in header_names:\n",
    "            val_len += len( metadata[ 'standard' ] ) - 1 \n",
    "           \n",
    "        vals = header_names.copy()\n",
    "        for name, search in metadata.items():\n",
    "            index = header_names.index( name )\n",
    "            \n",
    "            if name == 'standard':\n",
    "                # insert standard keys\n",
    "                vals[ index ] = get_standard_metadata_values( file, search )\n",
    "\n",
    "            else:\n",
    "                # custom key\n",
    "                if isinstance( search, dict ):\n",
    "                    pattern = search[ 'search' ]\n",
    "                    kwargs = search.copy()\n",
    "                    del kwargs[ 'search' ]\n",
    "                    \n",
    "                else:\n",
    "                    pattern = search\n",
    "                    kwargs = {}\n",
    "                \n",
    "                vals[ index ] = std.metadata_from_file_name( pattern, file, **kwargs )\n",
    "        \n",
    "        # fllatten standard keys\n",
    "        if 'standard' in header_names:\n",
    "            index = header_names.index( 'standard' )\n",
    "            vals = vals[ :index ] + vals[ index ] + vals[ index + 1: ]\n",
    "\n",
    "        return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Handle file metadata from Andor if present in file\n",
    "def import_datum( file, metadata = None, reindex = True, cps = False ):\n",
    "    \"\"\"\n",
    "    Imports data from a single Andor output files.\n",
    "    \n",
    "    :param file: The file path to read.\n",
    "    :param metadata: Metadata from the file name is turned into MultiIndex columns.\n",
    "        + If list, use standard keywords to include in index [ 'sample', 'power', 'wavelength', 'time' ]\n",
    "        + If Dictionary, keys indicate level name, value is either the pattern to match\n",
    "            or another dictionary with 'search' key being the pattern to match, and additional\n",
    "            entries matching arguments passed to standard_functions#metadata_from_filename.\n",
    "            + Reseserved key 'standard' can be provided with a list value to get standard metadata.\n",
    "    :param reindex: Use wavelength as index. [Default: True] \n",
    "    :param cps: Converts the data to counts per second. \n",
    "        A valid time string of the form XsX must be present.\n",
    "    :returns: A Pandas DataFrame with MultiIndexed columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_names = [ 'wavelength', 'counts' ] \n",
    "    \n",
    "    # check for metadata at end of file\n",
    "    file_metadata = ''\n",
    "    file_data = ''\n",
    "    for line in open( file ):\n",
    "        # check if line begins with a number\n",
    "        data_match = re.match( '^\\d', line )\n",
    "        if data_match is None:\n",
    "            # did not match numeric data, place in metadata\n",
    "            file_metadata += line\n",
    "            \n",
    "        else:\n",
    "            # numeric data\n",
    "            file_data += line\n",
    "\n",
    "    file_data = io.StringIO( file_data ) # turn data into file object for reading in\n",
    "    \n",
    "    if cps:\n",
    "        int_time = time_from_file_name( file )\n",
    "    \n",
    "    # no metadata, import file\n",
    "    if metadata is None:\n",
    "        df = pd.read_csv( file_data, names = data_names, header = None  )\n",
    "        \n",
    "        if cps:\n",
    "            df.counts /= int_time\n",
    "        \n",
    "        if reindex:\n",
    "            df = df.set_index( 'wavelength' )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # get metadata\n",
    "    f_name = os.path.basename( file )\n",
    "    \n",
    "    if isinstance( metadata, list ):\n",
    "        # use standard metadata\n",
    "        header_names = metadata.copy()\n",
    "\n",
    "    elif isinstance( metadata, dict ):        \n",
    "        header_names = list( metadata.keys() )\n",
    "        \n",
    "        if 'standard' in header_names:\n",
    "            # replace standard with values\n",
    "            index = header_names.index( 'standard' )\n",
    "            header_names = header_names[ :index ] + metadata[ 'standard' ] + header_names[ index + 1: ]\n",
    "    \n",
    "    header_names.append( 'metrics' )\n",
    "    \n",
    "    header_vals = get_metadata_values( os.path.basename( file ), metadata )\n",
    "    header_vals = [ [ val ] for val in header_vals ] # convert levels to lists for taking product\n",
    "    header_vals.append( data_names )\n",
    "    \n",
    "    header = pd.MultiIndex.from_product( header_vals, names = header_names )\n",
    "    \n",
    "    df = pd.read_csv( file_data, header = None )\n",
    "    \n",
    "    if cps:\n",
    "        df.iloc[ :, 1 ] /= int_time\n",
    "    \n",
    "    df.columns = header\n",
    "    \n",
    "    if reindex:\n",
    "        if metadata is None:\n",
    "            # simple index\n",
    "            df.set_index( 'wavelength' )\n",
    "            \n",
    "        else:\n",
    "            # multindex\n",
    "            df.index = df.xs( 'wavelength', level = 'metrics', axis = 1 ).values.flatten()\n",
    "            df.drop( 'wavelength', level = 'metrics', axis = 1, inplace = True )\n",
    "            df.columns = df.columns.droplevel( 'metrics' )\n",
    "        \n",
    "    return df\n",
    "            \n",
    "        \n",
    "        \n",
    "def import_data( \n",
    "    folder_path, \n",
    "    file_pattern = '*.csv', \n",
    "    metadata = None, \n",
    "    cps = False, \n",
    "    interpolate = 'linear', \n",
    "    fillna = 0 \n",
    "):\n",
    "    \"\"\"\n",
    "    Imports data from Andor output files.\n",
    "    \n",
    "    :param folder_path: The file path containing the data files\n",
    "    :param file_pattern: A glob pattern to filter the imported files [Default: '*']\n",
    "    :param metadata: Metadata from the file name is turned into MultiIndex columns.\n",
    "        + If list, use standard keywords to include in index \n",
    "            [ 'sample', 'power', 'wavelength', 'time', 'temperature' ]\n",
    "        + If Dictionary, keys indicate level name, value is pattern to match\n",
    "            + Reseserved key 'standard' can be provided with a list value to get standard metada\n",
    "    :param cps: Converts the data to counts per second. \n",
    "        A valid time string of the form XsX must be present.        \n",
    "    :param interpolate: How to interpolate data for a common index [Default: linear]\n",
    "        Use None to prevent reindexing\n",
    "    :param fillna: Value to fill NaN values with [Default: 0]\n",
    "    :returns: A Pandas DataFrame with MultiIndexed columns\n",
    "    :raises: RuntimeError if no files are found\n",
    "    \"\"\"\n",
    "    \n",
    "    # get dataframes from files\n",
    "    df = []\n",
    "    files = std.get_files( folder_path, file_pattern )\n",
    "    if len( files ) == 0:\n",
    "        # no files found\n",
    "        raise RuntimeError( 'No files found matching {}'.format( os.path.join( folder_path, file_pattern ) ) )\n",
    "    \n",
    "    for file in files:\n",
    "        data = import_datum( file, metadata = metadata, cps = cps ) # run local import datum function\n",
    "        df.append( data )\n",
    "        \n",
    "    if interpolate is not None:\n",
    "        df = std.common_reindex( df, how = interpolate, fillna = fillna )\n",
    "        \n",
    "    df = pd.concat( df, axis = 1 )\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def correct_spectra( df, correction ):\n",
    "    \"\"\"\n",
    "    Applies a correction spectral data.\n",
    "    \n",
    "    :param df: The Pandas DataFrame to correct.\n",
    "    :param correction: The correction data to apply.\n",
    "        Should be a tuple of ( camera, grating )\n",
    "        Camera values are [ 'idus' ]\n",
    "        Grating values are [ '300', '600' ]\n",
    "    :returns: The corrected data.\n",
    "    \"\"\"\n",
    "    data_path =  os.path.join( os.path.dirname( __file__ ), 'data', 'andor-corrections.pkl' )\n",
    "    cdf = pd.read_pickle( data_path )\n",
    "    \n",
    "    corrections = cdf.xs( ( 'grating', *correction ), axis = 1 )\n",
    "    cdf = std.common_reindex( [ df, corrections ] )\n",
    "    corrections = cdf[ 1 ].reindex( df.index )\n",
    "    \n",
    "    return df.multiply( corrections, axis = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
