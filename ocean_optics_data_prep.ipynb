{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ocean Optics Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import import_ipynb\n",
    "import standard_functions as std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_file_name( file ):\n",
    "    name_search  = '^(.*?)' # use lazy matching\n",
    "    return std.metadata_from_file_name( name_search, file, delimeter = '_' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_metadata_value( file, metadata ):\n",
    "    \"\"\"\n",
    "    Gets metadata values from a file path\n",
    "    \n",
    "    :param file: The file path to search\n",
    "    :param metadata: The key of a standard metadata to retrieve\n",
    "        [ 'sample' ]\n",
    "    :returns: A list of metadata values\n",
    "    \"\"\"\n",
    "    return getattr( sys.modules[ __name__ ], '{}_from_file_name'.format( metadata ) )( file )\n",
    "\n",
    "\n",
    "def get_standard_metadata_values( file, metadata ):\n",
    "    \"\"\"\n",
    "    Gets metadata values from a file path\n",
    "    \n",
    "    :param file: The file path to search\n",
    "    :param metadata: A list of standard metadata to retrieve\n",
    "        [ 'sample' ]\n",
    "    :returns: A list of metadata values\n",
    "    \"\"\"\n",
    "    return [ getattr( sys.modules[ __name__ ], '{}_from_file_name'.format( meta ) )( file ) for meta in metadata ]\n",
    "\n",
    "\n",
    "def get_metadata_values( file, metadata ):\n",
    "    \"\"\"\n",
    "    Gets metadata values from a file path.\n",
    "    \n",
    "    :param file: The file path to search.\n",
    "    :param metadata: Metadata from the file name is turned into MultiIndex columns.\n",
    "        + If list, use standard keywords to include in index [ 'sample' ]\n",
    "        + If Dictionary, keys indicate level name, value is pattern to match.\n",
    "            or another dictionary with 'search' key being the pattern to match, and additional\n",
    "            entries matching arguments passed to standard_functions#metadata_from_filename.\n",
    "            + Reseserved key 'standard' can be provided with a list value to get standard metadata.\n",
    "    :returns: A list of metadata values.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance( metadata, list ):\n",
    "        # use standard metadata\n",
    "        return get_standard_metadata_values( file, metadata )\n",
    "\n",
    "        \n",
    "    if isinstance( metadata, dict ):\n",
    "        # use custom metadata\n",
    "        # key is name, value is regexp pattern or dictionary with pattern and arguments\n",
    "\n",
    "        header_names = list( metadata.keys() )\n",
    "        \n",
    "        # get number of values\n",
    "        val_len = len( header_names )\n",
    "        if 'standard' in header_names:\n",
    "            val_len += len( metadata[ 'standard' ] ) - 1 \n",
    "           \n",
    "        vals = header_names.copy()\n",
    "        for name, search in metadata.items():\n",
    "            index = header_names.index( name )\n",
    "            \n",
    "            if name == 'standard':\n",
    "                # insert standard keys\n",
    "                vals[ index ] = get_standard_metadata_values( file, search )\n",
    "\n",
    "            else:\n",
    "                # custom key\n",
    "                if isinstance( search, dict ):\n",
    "                    pattern = search[ 'search' ]\n",
    "                    kwargs = search.copy()\n",
    "                    del kwargs[ 'search' ]\n",
    "                    \n",
    "                else:\n",
    "                    pattern = search\n",
    "                    kwargs = {}\n",
    "                \n",
    "                vals[ index ] = std.metadata_from_file_name( pattern, file, **kwargs )\n",
    "        \n",
    "        # fllatten standard keys\n",
    "        if 'standard' in header_names:\n",
    "            index = header_names.index( 'standard' )\n",
    "            vals = vals[ :index ] + vals[ index ] + vals[ index + 1: ]\n",
    "\n",
    "        return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_datum( file, time = False, cps = False, metadata = None, reindex = True ):\n",
    "    \"\"\"\n",
    "    Imports data from a single Ocean Optics spectrometer file.\n",
    "    \n",
    "    :param file: The file path to read.\n",
    "    :param time: Read the integration time in from the file as a header. [Default: False]\n",
    "    :param cps: Converts the data to counts per second. [Default: False]\n",
    "    :param metadata: Metadata from the file name is turned into MultiIndex columns.\n",
    "        + If list, use standard keywords to include in index. [ 'sample' ]\n",
    "        + If Dictionary, keys indicate level name, value is either the pattern to match\n",
    "            or another dictionary with 'search' key being the pattern to match, and additional\n",
    "            entries matching arguments passed to standard_functions#metadata_from_filename.\n",
    "            + Reseserved key 'standard' can be provided with a list value to get standard metadata\n",
    "    :param reindex: Use wavelength as index [Default: True] \n",
    "    :returns: A Pandas DataFrame with MultiIndexed columns\n",
    "    \"\"\"\n",
    "    def get_time_from_file( metadata ):\n",
    "        \"\"\"\n",
    "        Get integration time metadata from file.\n",
    "        \n",
    "        :param metadata: A list of metadata from the file.\n",
    "        :returns: The integration time.\n",
    "        \"\"\"\n",
    "        for prop, value in metadata.items():\n",
    "            if re.match( 'Integration Time', prop ):\n",
    "                # found integration time\n",
    "                return float( value )\n",
    "        \n",
    "        if 'time' not in header_names:\n",
    "            # did not find integration time\n",
    "            raise RuntimeError( 'Could not find integration time in file {}'.format( file ) )\n",
    "    \n",
    "    \n",
    "    data_names = [ 'wavelength', 'counts' ] \n",
    "    \n",
    "    # check for metadata at beginning of file\n",
    "    lines = [ line.rstrip( '\\n' ) for line in open( file ) ]\n",
    "    \n",
    "    # serach for data break\n",
    "    data_break = 'Begin Spectral Data'\n",
    "    break_line = None\n",
    "    for index, line in enumerate( lines ):\n",
    "        if re.search( data_break, line ):\n",
    "            break_line = index\n",
    "            break\n",
    "    \n",
    "    if break_line is not None:\n",
    "        # break line found, metadata above, data below\n",
    "        file_metadata = lines[ :break_line ]\n",
    "        file_metadata = [ line.split( ':', 1 ) for line in file_metadata ]\n",
    "        file_metadata = { d[ 0 ].strip(): d[ 1 ].strip() for d in file_metadata if len( d ) == 2 }  \n",
    "        \n",
    "    if cps or time:\n",
    "        int_time = get_time_from_file( file_metadata )\n",
    "    \n",
    "    # no metadata, import file\n",
    "    if ( metadata is None ) and ( time is False ):\n",
    "        df = pd.read_csv( \n",
    "            file, \n",
    "            names = data_names, \n",
    "            header = None, \n",
    "            skiprows = break_line,\n",
    "            sep = '\\t'\n",
    "        )\n",
    "        \n",
    "        if cps:\n",
    "            # divide counts by integration time\n",
    "            df = df/ [ 1, int_time ]\n",
    "        \n",
    "        if reindex:\n",
    "            df = df.set_index( 'wavelength' )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # include metadata\n",
    "    header_names = []\n",
    "    header_vals = []\n",
    "    \n",
    "    if metadata is not None:\n",
    "        # get metadata form file name\n",
    "        f_name = os.path.basename( file )\n",
    "\n",
    "        if isinstance( metadata, list ):\n",
    "            # use standard metadata\n",
    "            header_names = metadata.copy()\n",
    "\n",
    "        elif isinstance( metadata, dict ):        \n",
    "            header_names = list( metadata.keys() )\n",
    "\n",
    "            if 'standard' in header_names:\n",
    "                # replace standard with values\n",
    "                index = header_names.index( 'standard' )\n",
    "                header_names = header_names[ :index ] + metadata[ 'standard' ] + header_names[ index + 1: ]\n",
    "\n",
    "        header_vals = get_metadata_values( os.path.basename( file ), metadata )\n",
    "        header_vals = [ [ val ] for val in header_vals ] # convert levels to lists for taking product\n",
    "    \n",
    "    if time:\n",
    "        header_names.append( 'time' )\n",
    "        header_vals.append( [ int_time ] )\n",
    "               \n",
    "    header_vals.append( data_names )\n",
    "    header_names.append( 'metrics' )\n",
    "    \n",
    "    header = pd.MultiIndex.from_product( header_vals, names = header_names )\n",
    "    \n",
    "    df = pd.read_csv( \n",
    "        file, \n",
    "        header = None, \n",
    "        skiprows = break_line,\n",
    "        sep = '\\t'\n",
    "    )\n",
    "    \n",
    "    if cps:\n",
    "        df = df/ [ 1, int_time ]\n",
    "    \n",
    "    df.columns = header\n",
    "    \n",
    "    if reindex:\n",
    "        # multindex\n",
    "        df.index = df.xs( 'wavelength', level = 'metrics', axis = 1 ).values.flatten()\n",
    "        df.index = df.index.rename( 'wavelength' )\n",
    "        df.drop( 'wavelength', level = 'metrics', axis = 1, inplace = True )\n",
    "        df.columns = df.columns.droplevel( 'metrics' )\n",
    "        \n",
    "    return df\n",
    "        \n",
    "        \n",
    "def import_data( \n",
    "    folder_path, \n",
    "    file_pattern = '*.txt', \n",
    "    metadata = None,\n",
    "    time = False,\n",
    "    cps = False, \n",
    "    interpolate = 'linear', \n",
    "    fillna = 0\n",
    "):\n",
    "    \"\"\"\n",
    "    Imports data from Andor output files\n",
    "    \n",
    "    :param folder_path: The file path containing the data files\n",
    "    :param file_pattern: A glob pattern to filter the imported files [Default: '*']\n",
    "    :param metadata: Metadata from the file name is turned into MultiIndex columns.\n",
    "        + If list, use standard keywords to include in index \n",
    "            [ 'sample', 'power', 'wavelength', 'time', 'temperature' ]\n",
    "        + If Dictionary, keys indicate level name, value is pattern to match\n",
    "            + Reseserved key 'standard' can be provided with a list value to get standard metada\n",
    "    :param time: Read the integration time in from the file as a header. [Default: False]\n",
    "    :param cps: Converts the data to counts per second. \n",
    "        A valid time string of the form XsX must be present.        \n",
    "    :param interpolate: How to interpolate data for a common index [Default: linear]\n",
    "        Use None to prevent reindexing\n",
    "    :param fillna: Value to fill NaN values with [Default: 0]\n",
    "    :param reindex: Reindex the DataFrame using \n",
    "    :returns: A Pandas DataFrame with MultiIndexed columns\n",
    "    :raises: RuntimeError if no files are found\n",
    "    \"\"\"\n",
    "    \n",
    "    # get dataframes from files\n",
    "    df = []\n",
    "    files = std.get_files( folder_path, file_pattern )\n",
    "    if len( files ) == 0:\n",
    "        # no files found\n",
    "        raise RuntimeError( 'No files found matching {}'.format( os.path.join( folder_path, file_pattern ) ) )\n",
    "    \n",
    "    for file in files:\n",
    "        data = import_datum( \n",
    "            file, \n",
    "            metadata = metadata, \n",
    "            cps = cps, \n",
    "            time = time\n",
    "        ) # run local import datum function\n",
    "        df.append( data )\n",
    "        \n",
    "    if interpolate is not None:\n",
    "        df = std.common_reindex( df, how = interpolate, fillna = fillna )\n",
    "        \n",
    "    df = pd.concat( df, axis = 1 )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
